<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
  <head>
    <title>CSS Speech Module</title>
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type" >
    <link href="../default.css" rel="stylesheet" type="text/css" >
    <style type="text/css">
      p
      {
          padding-bottom : 1em;
      }

      p + p
      {
          text-indent : 0;
      }

      *:target
      {
          border : 1px dashed #66CC66;
      }</style>
    <!--
      .prod
      {
      font-family : inherit;
      font-size : inherit
      }

      pre.prod
      {
      white-space : pre-wrap;
      margin : 1em 0 1em 2em
      }

      code
      {
      font-size : inherit;
      }

      #box-shadow-samples td
      {
      background : white;
      color : black;
      }

      caption
      {
      text-align : left;
      font-weight : bold
      }

      .note
      {
      font-style : italic
      }

      .issue
      {
      color : maroon;
      font-style : italic
      }

      div.example pre
      {
      color : green;
      margin-left : 2em
      }

      dl
      {
      margin-left : 2em
      }

      caption dfn
      {
      font-size : 120%
      }
    -->
    <link href="https://www.w3.org/StyleSheets/TR/W3C-ED" rel="stylesheet" type="text/css" >
  </head>
  <body>
    <div class="head">
      <!--logo-->
      <h1 id="top">CSS Speech Module</h1>
      <h2 class="no-num no-toc">[LONGSTATUS] [DATE]</h2>
      <dl id="versions">
        <dt>This version:</dt>
        <dd>
          <!--<a href="https://www.w3.org/TR/[YEAR]/WD-[SHORTNAME]-[CDATE]/">[VERSION]</a>-->
          <a href="https://drafts.csswg.org/css3-speech">https://drafts.csswg.org/css3-speech</a>
        </dd>
        <dt>Latest version:</dt>
        <dd>
          <a href="https://www.w3.org/TR/css3-speech/">[LATEST]</a>
        </dd>
        <dt>Previous versions:</dt>
        <dd>
          <a href="https://www.w3.org/TR/2011/WD-css3-speech-20110818/"
            >https://www.w3.org/TR/2011/WD-css3-speech-20110818/</a>
        </dd>
        <dt>Feedback:
          <dd><a href="mailto:www-style@w3.org?subject=%5Bcss-speech%5D%20feedback">www-style@w3.org</a>
              with subject line &ldquo;<kbd>[css-speech] <var>&hellip; message topic &hellip;</var></kbd>&rdquo;
              (<a rel="discussion" href="http://lists.w3.org/Archives/Public/www-style/">archives</a>)

      </dl>
      <dl id="editors-list">
        <dt>Editor:</dt>
        <dd><a href="mailto:dweck@daisy.org">Daniel Weck</a> (<a href="http://www.daisy.org">DAISY
            Consortium</a>)</dd>
        <dt>Former editors:</dt>
        <dd><a href="mailto:dsr@w3.org">Dave Raggett</a> (<a href="http://www.w3.org/">W3C</a>/<a
            href="http://www.canon.com/">Canon</a>)</dd>
        <dd><a href="mailto:daniel@glazman.org">Daniel Glazman</a> (<a
            href="http://www.disruptive-innovations.com/">Disruptive Innovations</a>)</dd>
        <dd><a href="mailto:csant@opera.com">Claudio Santambrogio</a> (<a
            href="http://www.opera.com/">Opera Software</a>)</dd>
      </dl>
      <!--copyright-->
      <hr title="Separator for header">
    </div>
    <h2 class="no-num no-toc" id="abstract">Abstract</h2>
    <p>CSS (Cascading Style Sheets) is a language that describes the rendering of markup documents
      (e.g. HTML, XML) on various supports, such as screen, paper, speech, etc. The Speech module
      defines aural CSS properties that enable authors to declaratively control the rendering of
      documents via speech synthesis, and using optional audio cues. Note that this standard was
      developed in cooperation with the <a href="http://www.w3.org/Voice/">Voice Browser
        Activity</a>.</p>
    <h2 class="no-num no-toc" id="status">Status of this document</h2>
    <!--status-->
    <!-- <h3 class="no-num no-toc" id="maturity">Maturity Level</h3> -->
    <p> This document is based on the <a href="https://www.w3.org/TR/2011/WD-css3-speech-20110818/"
        >Last Call Working Draft (18 August 2011)</a> and includes changes that reflect the outcome
      of the <a href="http://wiki.csswg.org/spec/css3-speech">disposition of comments</a>. </p>
    <p>Before the specification can progress
      to <a href="http://www.w3.org/2005/10/Process-20051014/tr#cfr"
      >Proposed Recommendation,</a> the <a href="#exit">CR exit
      criteria</a> must be met. The specification will not become
      Proposed Recommendation before 20 September 2012. A test suite
      and an implementation report will be made during the Candidate
      Recommendation period. </p>
    <p id="at-risk">The following features are at-risk and may be dropped at the end of the
      Candidate Recommendation period if there has not been enough interest from implementers:
      'voice-balance', 'voice-duration', 'voice-pitch', 'voice-range', and 'voice-stress'. </p>
    <nav id="toc">
    <h2 class="no-num no-toc" id="contents">Table of contents</h2>
    <!--toc-->
    </nav>
    <h2 id="intro">Introduction, design goals</h2>
    <p class="note">Note that this section is informative.</p>
    <p>The aural presentation of information is commonly used by people who are blind,
      visually-impaired or otherwise print-disabled. For instance, "screen readers" allow users to
      interact with visual interfaces that would otherwise be inaccessible to them. There are also
      circumstances in which <em>listening</em> to content (as opposed to <em>reading</em>) is
      preferred, or sometimes even required, irrespective of a person's physical ability to access
      information. For instance: playing an e-book whilst driving a vehicle, learning how to
      manipulate industrial and medical devices, interacting with home entertainment systems,
      teaching young children how to read.</p>
    <p> The CSS properties defined in the Speech module enable authors to declaratively control the
      presentation of a document in the aural dimension. The aural rendering of a document combines
      speech synthesis (also known as "TTS", the acronym for "Text to Speech") and auditory icons
      (which are referred-to as "audio cues" in this specification). The CSS Speech properties
      provide the ability to control speech pitch and rate, sound levels, TTS voices, etc. These
      stylesheet properties can be used together with visual properties (mixed media), or as a
      complete aural alternative to a visual presentation. </p>
    <h2 id="background">Background information, CSS 2.1</h2>
    <p class="note">Note that this section is informative.</p>
    <p> The CSS Speech module is a re-work of the informative CSS2.1 Aural appendix, within which
      the "aural" media type was described, but also deprecated (in favor of the "speech" media
      type). Although the [[!CSS21]] specification reserves the "speech" media type, it doesn't
      actually define the corresponding properties. The Speech module describes the CSS properties
      that apply to the "speech" media type, and defines a new "box" model specifically for the
      aural dimension. </p>
    <p> Content creators can conditionally include CSS properties dedicated to user agents with text
      to speech synthesis capabilities, by specifying the "speech" media type via the
        <code>media</code> attribute of the <code>link</code> element, or with the
        <code>@media</code> at-rule, or within an <code>@import</code> statement. When styles are
      authored within the scope of such conditional statements, they are ignored by user agents that
      do not support the Speech module. </p>
    <h2 id="ssml-rel">Relationship with SSML</h2>
    <p class="note">Note that this section is informative.</p>
    <p>Some of the features in this specification are conceptually similar to functionality
      described in the Speech Synthesis Markup Language (SSML) Version 1.1 [[!SSML]]. However, the
      specificities of the CSS model mean that compatibility with SSML in terms of syntax and/or
      semantics is only partially achievable. The definition of each property in the Speech module
      includes informative statements, wherever necessary, to clarify their relationship with
      similar functionality from SSML.</p>
    <h2 id="css-values">CSS values</h2>

  <p>This specification follows the <a href="https://www.w3.org/TR/CSS21/about.html#property-defs">CSS property definition conventions</a> from [[!CSS2]].
  Value types not defined in this specification are defined in CSS Values & Units [[!CSS-VALUES-3]].
  Other CSS modules may expand the definitions of these value types.

  <p>In addition to the property-specific values listed in their definitions,
  all properties defined in this specification
  also accept the <a>CSS-wide keywords</a> keywords as their property value.
  For readability they have not been repeated explicitly.
    <h2 id="example">Example</h2>
    <div class="example">
      <p>This example shows how authors can tell the speech synthesizer to speak HTML headings with
        a voice called "paul", using "moderate" emphasis (which is more than normal) and how to
        insert an audio cue (pre-recorded audio clip located at the given URL) before the start of
        TTS rendering for each heading. In a stereo-capable sound system, paragraphs marked with the
        CSS class "heidi" are rendered on the left audio channel (and with a female voice, etc.),
        whilst the class "peter" corresponds to the right channel (and to a male voice, etc.). The
        volume level of text spans marked with the class "special" is lower than normal, and a
        prosodic boundary is created by introducing a strong pause after it is spoken (note how the
          <code>span</code> inherits the voice-family from its parent paragraph).</p>
      <pre>
h1, h2, h3, h4, h5, h6
{
  voice-family: paul;
  voice-stress: moderate;
  cue-before: url(../audio/ping.wav);
  voice-volume: medium 6dB;
}
p.heidi
{
  voice-family: female;
  voice-balance: left;
  voice-pitch: high;
  voice-volume: -6dB;
}
p.peter
{
  voice-family: male;
  voice-balance: right;
  voice-rate: fast;
}
span.special
{
  voice-volume: soft;
  pause-after: strong;
}

...

&lt;h1&gt;I am Paul, and I speak headings.&lt;/h1&gt;
&lt;p class="heidi"&gt;Hello, I am Heidi.&lt;/p&gt;
&lt;p class="peter"&gt;
  &lt;span class="special"&gt;Can you hear me ?&lt;/span&gt;
  I am Peter.
&lt;/p&gt;</pre>
    </div>
    <h2 id="aural-model">The aural formatting model</h2>
    <p>The CSS formatting model for aural media is based on a sequence of sounds and silences that
      occur within a nested context similar to the <a href="#box-model-def">visual box model</a>,
      which we name the <dfn id="aural-box-model">aural "box" model</dfn>. The aural "canvas"
      consists of a two-channel (stereo) space and of a temporal dimension, within which synthetic
      speech and audio cues coexist. The selected element is surrounded by 'rest', 'cue' and 'pause'
      properties (from the innermost to the outermost position). These can be seen as aural
      equivalents to 'padding', 'border' and 'margin', respectively. When used, the ':before' and
      ':after' pseudo-elements [[!CSS21]] get inserted between the element's contents and the
      'rest'. </p>
    <p> The following diagram illustrates the equivalence between properties of the visual and aural
      box models, applied to the selected &lt;element&gt;:</p>
    <p>
      <img
        title="The aural 'box' model, illustrated by a diagram: the selected element is positioned in the center, on its left side are (from innermost to outermost) rest-before, cue-before, pause-before, on its right side are (from innermost to outermost) rest-after, cue-after, pause-after, where rest is conceptually similar to padding, cue is similar to border, pause is similar to margin."
        alt="The aural 'box' model, illustrated by a diagram: the selected element is positioned in the center, on its left side are (from innermost to outermost) rest-before, cue-before, pause-before, on its right side are (from innermost to outermost) rest-after, cue-after, pause-after, where rest is conceptually similar to padding, cue is similar to border, pause is similar to margin."
        id="aural-box" src="aural-box.png" />
    </p>
    <h2 id="mixing-props">Mixing properties</h2>
    <h3 id="mixing-props-voice-volume">The 'voice-volume' property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="voice-volume">voice-volume</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>silent | [[x-soft | soft | medium | loud | x-loud] || &lt;decibel&gt;] </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>medium</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>yes</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>'silent', or a keyword value and optionally also a decibel offset (if not zero)</td>
        </tr>
      </tbody>
    </table>
    <p>The 'voice-volume' property allows authors to control the amplitude of the audio waveform
      generated by the speech synthesiser, and is also used to adjust the relative volume level of
        <a href="#cue-props">audio cues</a> within the <a href="#aural-model">aural box model</a> of
      the selected element. </p>
    <p class="note"> Note that although the functionality provided by this property is similar to
      the <a href="https://www.w3.org/TR/speech-synthesis11/#edef_prosody"><code>volume</code>
        attribute of the <code>prosody</code> element</a> from the SSML markup language [[!SSML]],
      there are notable discrepancies. For example, CSS Speech volume keywords and decibels units
      are not mutually-exclusive, due to how values are inherited and combined for selected
      elements. </p>
    <dl>
      <!-- dt>
        <strong>normal</strong>
      </dt>
      <dd>
        <p> Corresponds to +0.0dB, which means that there is no modification of volume level. This
          value overrides the inherited value.</p>
      </dd -->
      <dt>
        <strong>silent</strong>
      </dt>
      <dd>
        <p> Specifies that no sound is generated (the text is read "silently").</p>
        <p class="note"> Note that this has the same effect as using negative infinity decibels.
          Also note that there is a difference between an element whose 'voice-volume' property has
          a value of 'silent', and an element whose 'speak' property has the value 'none'. With the
          former, the selected element takes up the same time as if it was spoken, including any
          pause before and after the element, but no sound is generated (descendants within the <a
            href="#aural-model">aural box model</a> of the selected element can override the
          'voice-volume' value, and may therefore generate audio output). With the latter, the
          selected element is not rendered in the aural dimension and no time is allocated for
          playback (descendants within the <a href="#aural-model">aural box model</a> of the
          selected element can override the 'speak' value, and may therefore generate audio output).
        </p>
      </dd>
      <dt><strong>x-soft</strong>, <strong>soft</strong>, <strong>medium</strong>,
          <strong>loud</strong>, <strong>x-loud</strong></dt>
      <dd>
        <p>This sequence of keywords corresponds to monotonically non-decreasing volume levels,
          mapped to implementation-dependent values that meet the listener's requirements with
          regards to perceived loudness. These audio levels are typically provided via a preference
          mechanism that allow users to calibrate sound options according to their auditory
          environment. The keyword 'x-soft' maps to the user's <em>minimum audible</em> volume
          level, 'x-loud' maps to the user's <em>maximum tolerable</em> volume level, 'medium' maps
          to the user's <em>preferred</em> volume level, 'soft' and 'loud' map to intermediary
          values.</p>
      </dd>
      <dt>
        <strong>&lt;decibel&gt;</strong>
      </dt>
      <dd>
        <p>A <a href="#number-def">number</a> immediately followed by "dB" (decibel unit). This
          represents a change (positive or negative) relative to the given keyword value (see
          enumeration above), or to the default value for the root element, or otherwise to the
          inherited volume level (which may itself be a combination of a keyword value and of a
          decibel offset, in which case the decibel values are combined additively). When the
          inherited volume level is 'silent', this 'voice-volume' resolves to 'silent' too,
          regardless of the specified &lt;decibel&gt; value. Decibels represent the ratio of the
          squares of the new signal amplitude (a1) and the current amplitude (a0), as per the
          following logarithmic equation: volume(dB) = 20 log10 (a1 / a0) </p>
        <p class="note"> Note that -6.0dB is approximately half the amplitude of the audio signal,
          and +6.0dB is approximately twice the amplitude.</p>
      </dd>
    </dl>
    <p class="note">Note that perceived loudness depends on various factors, such as the listening
      environment, user preferences or physical abilities. The effective volume variation between
      'x-soft' and 'x-loud' represents the dynamic range (in terms of loudness) of the audio output.
      Typically, this range would be compressed in a noisy context, i.e. the perceived loudness
      corresponding to 'x-soft' would effectively be closer to 'x-loud' than it would be in a quiet
      environment. There may also be situations where both 'x-soft' and 'x-loud' would map to low
      volume levels, such as in listening environments requiring discretion (e.g. library,
      night-reading). </p>
    <h3 id="mixing-props-voice-balance">The 'voice-balance' property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="voice-balance">voice-balance</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;number&gt; | left | center | right | leftwards | rightwards </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>center</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>yes</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>the specified value resolved to a &lt;number&gt; between '-100' and '100'
            (inclusive)</td>
        </tr>
      </tbody>
    </table>
    <p> The 'voice-balance' property controls the spatial distribution of audio output across a
      lateral sound stage: one extremity is on the left, the other extremity is on the right hand
      side, relative to the listener's position. Authors can specify intermediary steps between left
      and right extremities, to represent the audio separation along the resulting left-right axis. </p>
    <p class="note"> Note that the functionality provided by this property has no match in the SSML
      markup language [[!SSML]]. </p>
    <dl>
      <dt>
        <strong>&lt;number&gt;</strong>
      </dt>
      <dd>
        <p>A <a href="#number-def">number</a> between '-100' and '100' (inclusive). Values smaller
          than '-100' are clamped to '-100'. Values greater than '100' are clamped to '100'. The
          value '-100' represents the left side, and the value '100' represents the right side. The
          value '0' represents the center point whereby there is no discernible audio separation
          between left and right sides (in a stereo sound system, this corresponds to equal
          distribution of audio signals between left and right speakers). </p>
      </dd>
      <dt>
        <strong>left</strong>
      </dt>
      <dd>
        <p>Same as '-100'.</p>
      </dd>
      <dt>
        <strong>center</strong>
      </dt>
      <dd>
        <p>Same as '0'.</p>
      </dd>
      <dt>
        <strong>right</strong>
      </dt>
      <dd>
        <p>Same as '100'.</p>
      </dd>
      <dt>
        <strong>leftwards</strong>
      </dt>
      <dd>
        <p>Moves the sound to the left, by subtracting 20 from the inherited 'voice-balance' value,
          and by clamping the resulting number to '-100'.</p>
      </dd>
      <dt>
        <strong>rightwards</strong>
      </dt>
      <dd>
        <p>Moves the sound to the right, by adding 20 to the inherited 'voice-balance' value, and by
          clamping the resulting number to '100'.</p>
      </dd>
    </dl>
    <p> user agents may be connected to different kinds of sound systems, featuring varying audio
      mixing capabilities. The expected behavior for mono, stereo, and surround sound systems is
      defined as follows: </p>
    <ul>
      <li> When user agents produce audio via a mono-aural sound system (i.e. single-speaker setup),
        the 'voice-balance' property has no effect. </li>
      <li> When user agents produce audio through a stereo sound system (e.g. two speakers, a pair
        of headphones), the left-right distribution of audio signals can precisely match the
        authored values for the 'voice-balance' property. </li>
      <li> When user agents are capable of mixing audio signals through more than 2 channels (e.g.
        5-speakers surround sound system, including a dedicated center channel), the physical
        distribution of audio signals resulting from the application of the 'voice-balance' property
        should be performed so that the listener perceives sound as if it was coming from a basic
        stereo layout. For example, the center channel as well as the left/right speakers may be
        used altogether in order to emulate the behavior of the 'center' value. </li>
    </ul>
    <p> Future revisions of the CSS Speech module may include support for three-dimensional audio,
      which would effectively enable authors to specify "azimuth" and "elevation" values. In the
      future, content authored using the current specification may therefore be consumed by user
      agents which are compliant with the version of CSS Speech that supports three-dimensional
      audio. In order to prepare for this possibility, the values enabled by the current
      'voice-balance' property are designed to remain compatible with "azimuth" angles. More
      precisely, the mapping between the current left-right audio axis (lateral sound stage) and the
      envisioned 360 degrees plane around the listener's position is defined as follows: </p>
    <ul>
      <li>The value '0' maps to zero degrees ('center'). This is in "front" of the listener, not
        from "behind".</li>
      <li>The value '-100' maps to -40 degrees ('left'). Negative angles are in the
        counter-clockwise direction (the audio stage is seen from the top).</li>
      <li>The value '100' maps to 40 degrees ('right'). Positive angles are in the clockwise
        direction (the audio stage is seen from the top).</li>
      <li>Intermediary values on the scale from '-100' to '100' map to the angles between -40 and 40
        degrees in a numerically linearly-proportional manner. For example, '-50' maps to -20
        degrees.</li>
    </ul>
    <p class="note"> Note that sound systems may be configured by users in such a way that it would
      interfere with the left-right audio distribution specified by document authors. Typically, the
      various "surround" modes available in modern sound systems (including systems based on basic
      stereo speakers) tend to greatly alter the perceived spatial arrangement of audio signals. The
      illusion of a three-dimensional sound stage is often achieved using a combination of phase
      shifting, digital delay, volume control (channel mixing), and other techniques. Some users may
      even configure their system to "downgrade" any rendered sound to a single mono channel, in
      which case the effect of the 'voice-balance' property would obviously not be perceivable at
      all. The rendering fidelity of authored content is therefore dependent on such user
      customizations, and the 'voice-balance' property merely specifies the desired end-result. </p>
    <p class="note"> Note that many speech synthesizers only generate mono sound, and therefore do
      not intrinsically support the 'voice-balance' property. The sound distribution along the
      left-right axis consequently occurs at post-synthesis stage (when the speech-enabled user
      agent mixes the various audio sources authored within the document) </p>
    <h2 id="speaking-props">Speaking properties</h2>
    <h3 id="speaking-props-speak">The 'speak' property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="speak">speak</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>auto | never | always </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>auto</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>yes</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>specified value</td>
        </tr>
      </tbody>
    </table>
    <p>The 'speak' property determines whether or not to render text aurally.</p>
    <p class="note"> Note that the functionality provided by this property has no match in the SSML
      markup language [[!SSML]]. </p>
    <dl>
      <dt>
        <strong>auto</strong>
      </dt>
      <dd>
        <p>Resolves to a computed value of ''never''
           when <a href="#display-def">'display'</a> is 'none',
           otherwise resolves to a computed value of 'auto'.
           The used value is then equivalent to ''always'' if 'visibility' is ''visible''
           and to ''never'' otherwise.
        <p class="note"> Note that the 'none' value of the <a href="#display-def">'display'</a>
          property cannot be overridden by descendants of the selected element, but the 'auto' value
          of 'speak' can however be overridden using either of 'never' or 'always'. </p>
      </dd>
      <dt>
        <strong>never</strong>
      </dt>
      <dd>
        <p> This value causes an element (including pauses, cues, rests and actual content) to not
          be rendered (i.e., the element has no effect in the aural dimension).</p>
        <p class="note"> Note that any of the descendants of the affected element are allowed to
          override this value, so descendants can actually take part in the aural rendering despite
          using ''display: none'' at this level. However, the pauses, cues, and rests of the ancestor element
          remain "deactivated" in the aural dimension, and therefore do not contribute to the <a
            href="#collapsed-pauses">collapsing of pauses</a> or additive behavior of adjoining
          rests. </p>
      </dd>
      <dt>
        <strong>always</strong>
      </dt>
      <dd>
        <p> The element is rendered aurally
          (regardless of its <a href="#display-def">'display'</a> value,
          or the <a href="#display-def">'display'</a> or 'speak' values of its ancestors).</p>
        <p class="note"> Note that using this value can result in the element being rendered in the
          aural dimension even though it would not be rendered on the visual canvas. </p>
      </dd>
    </dl>
    <h3 id="speaking-props-speak-as">The 'speak-as' property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="speak-as">speak-as</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>normal | spell-out || digits || [ literal-punctuation | no-punctuation ] </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>normal</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>yes</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>specified value</td>
        </tr>
      </tbody>
    </table>
    <p>The 'speak-as' property determines in what manner text gets rendered aurally, based upon a
      predefined list of possibilities.</p>
    <p class="note"> Note that the functionality provided by this property is conceptually similar
      to the <a href="https://www.w3.org/TR/speech-synthesis11/#edef_say-as"><code>say-as</code>
        element</a> from the SSML markup language [[!SSML]] (whose possible values are described in
      the [[SSML-SAYAS]] W3C Note). Although the design goals are similar, the CSS model is limited
      to a basic set of pronunciation rules.</p>
    <dl>
      <dt>
        <strong>normal</strong>
      </dt>
      <dd>
        <p>Uses language-dependent pronunciation rules for rendering the element's content. For
          example, punctuation is not spoken as-is, but instead rendered naturally as appropriate
          pauses.</p>
      </dd>
      <dt>
        <strong>spell-out</strong>
      </dt>
      <dd>
        <p>Spells the text one letter at a time (useful for acronyms and abbreviations). In
          languages where accented characters are rare, it is permitted to drop accents in favor of
          alternative unaccented spellings. As as example, in English, the word "r&ocirc;le" can
          also be written as "role". A conforming implementation would thus be able to spell-out
          "r&ocirc;le" as "R O L E".</p>
      </dd>
      <dt>
        <strong>digits</strong>
      </dt>
      <dd>
        <p>Speak numbers one digit at a time, for instance, "twelve" would be spoken as "one two",
          and "31" as "three one".</p>
        <p class="note">Speech synthesizers are knowledgeable about what a <em>number</em> is. The
          'speak-as' property enables some level of control on how user agents render numbers, and
          may be implemented as a preprocessing step before passing the text to the actual speech
          synthesizer.</p>
      </dd>
      <dt>
        <strong>literal-punctuation</strong>
      </dt>
      <dd>
        <p> Punctuation such as semicolons, braces, and so on is named aloud (i.e. spoken literally)
          rather than rendered naturally as appropriate pauses.</p>
      </dd>
      <dt>
        <strong>no-punctuation</strong>
      </dt>
      <dd>
        <p>Punctuation is not rendered: neither spoken nor rendered as pauses.</p>
      </dd>
    </dl>
    <h2 id="pause-props">Pause properties </h2>
    <h3 id="pause-props-pause-before-after">The 'pause-before' and 'pause-after' properties</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="pause-before">pause-before</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;time&gt; | none | x-weak | weak | medium | strong | x-strong </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>none</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>no</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>specified value</td>
        </tr>
      </tbody>
    </table>
    <p>&nbsp;</p>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="pause-after">pause-after</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;time&gt; | none | x-weak | weak | medium | strong | x-strong </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>none</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>no</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>specified value</td>
        </tr>
      </tbody>
    </table>
    <p>The 'pause-before' and 'pause-after' properties specify a prosodic boundary (silence with a
      specific duration) that occurs before (or after) the speech synthesis rendition of the
      selected element, or if any 'cue-before' (or 'cue-after') is specified, before (or after) the
      cue within the <a href="#aural-model">aural box model</a>.</p>
    <p class="note"> Note that although the functionality provided by this property is similar to
      the <a href="https://www.w3.org/TR/speech-synthesis11/#edef_break"><code>break</code>
        element</a> from the SSML markup language [[!SSML]], the application of 'pause' prosodic
      boundaries within the <a href="#aural-model">aural box model</a> of CSS Speech requires
      special considerations (e.g. <a href="#collapsed-pauses">"collapsed" pauses</a>). </p>
    <dl>
      <dt>
        <strong>&lt;time&gt;</strong>
      </dt>
      <dd>
        <p>Expresses the pause in absolute <a href="#time-def">time</a> units (seconds and
          milliseconds, e.g. "+3s", "250ms"). Only non-negative values are allowed.</p>
      </dd>
      <dt>
        <strong>none</strong>
      </dt>
      <dd>
        <p> Equivalent to 0ms (no prosodic break is produced by the speech processor). </p>
      </dd>
      <dt>
        <strong>x-weak</strong>, <strong>weak</strong>, <strong>medium</strong>,
          <strong>strong</strong>, and <strong>x-strong</strong>
      </dt>
      <dd>
        <p> Expresses the pause by the strength of the prosodic break in speech output. The exact
          time is implementation-dependent. The values indicate monotonically non-decreasing
          (conceptually increasing) break strength between elements. </p>
      </dd>
    </dl>
    <p class="note"> Note that stronger content boundaries are typically accompanied by pauses. For
      example, the breaks between paragraphs are typically much more substantial than the breaks
      between words within a sentence. </p>
    <div class="example">
      <p> This example illustrates how the default strengths of prosodic breaks for specific
        elements (which are defined by the user agent stylesheet) can be overridden by authored
        styles. </p>
      <pre>
p { pause: none } /* pause-before: none; pause-after: none */</pre>
    </div>
    <h3 id="pause-props-pause">The 'pause' shorthand property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="pause">pause</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;'pause-before'&gt; &lt;'pause-after'&gt;?</td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>N/A (see individual properties)</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>no</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>N/A (see individual properties)</td>
        </tr>
      </tbody>
    </table>
    <p>The 'pause' property is a shorthand property for 'pause-before' and 'pause-after'. If two
      values are given, the first value is 'pause-before' and the second is 'pause-after'. If only
      one value is given, it applies to both properties.</p>
    <div class="example">
      <p> Examples of property values:</p>
      <pre>
h1 { pause: 20ms; } /* pause-before: 20ms; pause-after: 20ms */
h2 { pause: 30ms 40ms; } /* pause-before: 30ms; pause-after: 40ms */
h3 { pause-after: 10ms; } /* pause-before: <i>unspecified</i>; pause-after: 10ms */</pre>
    </div>
    <h3 id="collapsed-pauses">Collapsing pauses</h3>
    <p> The pause defines the minimum distance of the aural "box" to the aural "boxes" before and
      after it. Adjoining pauses are merged by selecting the strongest named break and the longest
      absolute time interval. For example, "strong" is selected when comparing "strong" and "weak",
      "1s" is selected when comparing "1s" and "250ms", and "strong" and "250ms" take effect
      additively when comparing "strong" and "250ms". </p>
    <p>The following pauses are adjoining:</p>
    <ol>
      <li>The 'pause-after' of an aural "box" and the 'pause-after' of its last child, provided the
        former has no 'rest-after' and no 'cue-after'.</li>
      <li>The 'pause-before' of an aural "box" and the 'pause-before' of its first child, provided
        the former has no 'rest-before' and no 'cue-before'.</li>
      <li>The 'pause-after' of an aural "box" and the 'pause-before' of its next sibling.</li>
      <li>The 'pause-before' and 'pause-after' of an aural "box", if the the "box" has a
        'voice-duration' of "0ms" and no 'rest-before' or 'rest-after' and no 'cue-before' or
        'cue-after', or if the the "box" has no rendered content at all (see 'speak').</li>
    </ol>
    <p>A collapsed pause is considered adjoining to another pause if any of its component pauses is
      adjoining to that pause.</p>
    <p class="note"> Note that 'pause' has been moved from between the element's contents and any
      'cue' to outside the 'cue'. This is not backwards compatible with the informative CSS2.1 Aural
      appendix [[!CSS21]].</p>
    <h2 id="rest-props">Rest properties</h2>
    <h3 id="rest-props-rest-before-after">The 'rest-before' and 'rest-after' properties</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="rest-before">rest-before</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;time&gt; | none | x-weak | weak | medium | strong | x-strong </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>none</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>no</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>specified value</td>
        </tr>
      </tbody>
    </table>
    <p>&nbsp;</p>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="rest-after">rest-after</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;time&gt; | none | x-weak | weak | medium | strong | x-strong </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>none</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>no</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>specified value</td>
        </tr>
      </tbody>
    </table>
    <p>The 'rest-before' and 'rest-after' properties specify a prosodic boundary (silence with a
      specific duration) that occurs before (or after) the speech synthesis rendition of an element
      within the <a href="#aural-model">aural box model</a>. </p>
    <p class="note"> Note that although the functionality provided by this property is similar to
      the <a href="https://www.w3.org/TR/speech-synthesis11/#edef_break"><code>break</code>
        element</a> from the SSML markup language [[!SSML]], the application of 'rest' prosodic
      boundaries within the <a href="#aural-model">aural box model</a> of CSS Speech requires
      special considerations (e.g. interspersed audio cues, additive adjacent rests). </p>
    <dl>
      <dt>
        <strong>&lt;time&gt;</strong>
      </dt>
      <dd>
        <p>Expresses the rest in absolute <a href="#time-def">time</a> units (seconds and
          milliseconds, e.g. "+3s", "250ms"). Only non-negative values are allowed.</p>
      </dd>
      <dt>
        <strong>none</strong>
      </dt>
      <dd>
        <p> Equivalent to 0ms (no prosodic break is produced by the speech processor). </p>
      </dd>
      <dt>
        <strong>x-weak</strong>, <strong>weak</strong>, <strong>medium</strong>,
          <strong>strong</strong>, and <strong>x-strong</strong>
      </dt>
      <dd>
        <p> Expresses the rest by the strength of the prosodic break in speech output. The exact
          time is implementation-dependent. The values indicate monotonically non-decreasing
          (conceptually increasing) break strength between elements.</p>
      </dd>
    </dl>
    <p>As opposed to <a href="#pause-props">pause properties</a>, the rest is inserted between the
      element's content and any 'cue-before' or 'cue-after' content. Adjoining rests are treated
      additively, and do not collapse.</p>
    <h3 id="rest-props-rest">The 'rest' shorthand property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="rest">rest</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;'rest-before'&gt; &lt;'rest-after'&gt;?</td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>N/A (see individual properties)</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>no</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>N/A (see individual properties)</td>
        </tr>
      </tbody>
    </table>
    <p>The 'rest' property is a shorthand for 'rest-before' and 'rest-after'. If two values are
      given, the first value is 'rest-before' and the second is 'rest-after'. If only one value is
      given, it applies to both properties.</p>
    <h2 id="cue-props">Cue properties</h2>
    <h3 id="cue-props-cue-before-after">The 'cue-before' and 'cue-after' properties</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="cue-before">cue-before</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;uri&gt; &lt;decibel&gt;? | none </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>none</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>no</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>specified value</td>
        </tr>
      </tbody>
    </table>
    <p>&nbsp;</p>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="cue-after">cue-after</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;uri&gt; &lt;decibel&gt;? | none </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>none</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>no</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>specified value</td>
        </tr>
      </tbody>
    </table>
    <p>The 'cue-before' and 'cue-after' properties specify auditory icons (i.e. pre-recorded /
      pre-generated sound clips) to be played before (or after) the selected element within the <a
        href="#aural-model">aural box model</a>.</p>
    <p class="note"> Note that although the functionality provided by this property may appear
      related to the <a href="https://www.w3.org/TR/speech-synthesis11/#edef_audio"
          ><code>audio</code> element</a> from the SSML markup language [[!SSML]], there are in fact
      major discrepancies. For example, the <a href="#aural-model">aural box model</a> means that
      audio cues are associated to the selected element's volume level, and CSS Speech's auditory
      icons provide limited functionality compared to SSML's <code>audio</code> element. </p>
    <dl>
      <dt>
        <strong>&lt;uri&gt;</strong>
      </dt>
      <dd>
        <p>The URI designates an auditory icon resource. When a user agent is not able to render the
          specified auditory icon (e.g. missing file resource, or unsupported audio codec), it is
          recommended to produce an alternative cue, such as a bell sound.</p>
      </dd>
      <dt>
        <strong>none</strong>
      </dt>
      <dd>
        <p>Specifies that no auditory icon is used.</p>
      </dd>
      <dt>
        <strong>&lt;decibel&gt;</strong>
      </dt>
      <dd>
        <p>A <a href="#number-def">number</a> immediately followed by "dB" (decibel unit). This
          represents a change (positive or negative) relative to the computed value of the
          'voice-volume' property within the <a href="#aural-model">aural box model</a> of the
          selected element (as a result, the volume level of an audio cue changes when the
          'voice-volume' property changes). When omitted, the implied value computes to 0dB. </p>
        <p> When the computed value of the 'voice-volume' property is 'silent', the audio cue is
          also set to 'silent' (regardless of this specified &lt;decibel&gt; value). Otherwise (when
          not 'silent'), 'voice-volume' values are always specified relatively to the volume level
          keywords (see the definition of 'voice-volume'), which map to a user-calibrated scale of
          "preferred" loudness settings. If the inherited 'voice-volume' value already contains a
          decibel offset, the dB offset specific to the audio cue is combined additively. </p>
        <p> Decibels express the ratio of the squares of the new signal amplitude (a1) and the
          current amplitude (a0), as per the following logarithmic equation: volume(dB) = 20 log10
          (a1 / a0) </p>
        <p class="note"> Note that -6.0dB is approximately half the amplitude of the audio signal,
          and +6.0dB is approximately twice the amplitude.</p>
        <p class="note"> Note that there is a difference between an audio cue whose volume is set to
          'silent' and one whose value is 'none'. In the former case, the audio cue takes up the
          same time as if it had been played, but no sound is generated. In the latter case, the
          there is no manifestation of the audio cue at all (i.e. no time is allocated for the cue
          in the aural dimension). </p>
      </dd>
    </dl>
    <div class="example">
      <p> Examples of property values:</p>
      <pre>
a
{
  cue-before: url(/audio/bell.aiff) -3dB;
  cue-after: url(dong.wav);
}

h1
{
  cue-before: url(../clips-1/pop.au) +6dB;
  cue-after: url(../clips-2/pop.au) 6dB;
}

div.caution { cue-before: url(./audio/caution.wav) +8dB; }</pre>
    </div>
    <h3 id="cue-props-volume">Relation between audio cues and speech synthesis volume levels</h3>
    <p class="note">Note that this section is informative.</p>

    <p> The volume levels of audio cues and of speech synthesis within the <a href="#aural-model"
        >aural box model</a> of a selected element are related. For example, the desired effect of
      an audio cue whose volume level is set at +0dB (as specified by the &lt;decibel&gt; value) is
      that its perceived loudness during playback is close to that of the speech synthesis rendition
      of the selected element, as dictated by the computed value of the 'voice-volume' property.
      Note that a 'silent' computed value for the 'voice-volume' property results in audio cues
      being "forcefully" silenced as well (i.e. regardless of the specified audio cue 'decibel'
      value) </p>

    <p> The volume keywords of the 'voice-volume' property are user-calibrated to match requirements
      not known at authoring time (e.g. auditory environment, personal preferences). Therefore, in
      order to achieve this approximate loudness alignment of audio cues and speech synthesis,
      authors should ensure that the volume level of audio cues (on average, as there may be
      discrete variations of perceived loudness due to changes in the audio stream, such as
      intonation, stress, etc.) matches the output of a speech synthesis rendition based on the
      'voice-family' intended for use, given "typical" listening conditions (i.e. default system
      volume levels, centered equalization across the frequency spectrum). As speech processors are
      capable of directly controlling the waveform amplitude of generated text-to-speech audio, and
      because user agents are able to adjust the volume output of audio cues (i.e. amplify or
      attenuate audio signals based on the intrinsic waveform amplitude of digitized sound clips),
      this sets a baseline that enables implementations to manage the loudness of both TTS and cue
      audio streams within the aural box model, relative to user-calibrated volume levels (see the
      keywords defined in the 'voice-volume' property). </p>

    <p> Due to the complex relationship between perceived audio characteristics (e.g. loudness) and
      the processing applied to the digitized audio signal (e.g. signal compression), we refer to a
      simple scenario whereby the attenuation is indicated in decibels, typically ranging from 0dB
      (i.e. maximum audio input, near clipping threshold) to -60dB (i.e. total silence). Given this
      context, a "standard" audio clip would oscillate between these values, the loudest peak levels
      would be close to -3dB (to avoid distortion), and the relevant audible passages would have
      average (RMS) volume levels as high as possible (i.e. not too quiet, to avoid background noise
      during amplification). This would roughly provide an audio experience that could be seamlessly
      combined with text-to-speech output (i.e. there would be no discernible difference in volume
      levels when switching from pre-recorded audio to speech synthesis). Although there exists no
      industry-wide standard to support such convention, different TTS engines tend to generate
      comparably-loud audio signals when no gain or attenuation is specified. For voice and soft
      music, -15dB RMS seems to be pretty standard. </p>
    <h3 id="cue-props-cue">The 'cue' shorthand property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="cue">cue</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;'cue-before'&gt; &lt;'cue-after'&gt;?</td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>N/A (see individual properties)</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>no</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>N/A (see individual properties)</td>
        </tr>
      </tbody>
    </table>
    <p>The 'cue' property is a shorthand for 'cue-before' and 'cue-after'. If two values are given
      the first value is 'cue-before' and the second is 'cue-after'. If only one value is given, it
      applies to both properties.</p>
    <div class="example">
      <p> Example of shorthand notation:</p>
      <pre>
h1
{
  cue-before: url(pop.au);
  cue-after: url(pop.au);
}
/* ...is equivalent to: */
h1
{
  cue: url(pop.au);
}</pre>
    </div>
    <h2 id="voice-char-props">Voice characteristic properties</h2>
    <h3 id="voice-props-voice-family">The 'voice-family' property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="voice-family">voice-family</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td> [[&lt;name&gt; | &lt;generic-voice&gt;],]* [&lt;name&gt; | &lt;generic-voice&gt;] |
            preserve </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>implementation-dependent</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>yes</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>specified value</td>
        </tr>
      </tbody>
    </table>
    <p>The 'voice-family' property specifies a prioritized list of component values that are
      separated by commas to indicate that they are alternatives (this is analogous to '<a
        href="#font-family-def"><code class="property">font-family</code></a>' in visual style
      sheets). Each component value potentially designates a speech synthesis voice instance, by
      specifying match criteria (see the <a href="#voice-selection">voice selection</a> section on
      this topic). </p>
    <p>
      <strong>&lt;generic-voice&gt;</strong> = [&lt;age&gt;? &lt;gender&gt; &lt;integer&gt;?] </p>
    <p class="note"> Note that although the functionality provided by this property is similar to
      the <a href="https://www.w3.org/TR/speech-synthesis11/#edef_voice"><code>voice</code>
        element</a> from the SSML markup language [[!SSML]], CSS Speech does not provide an
      equivalent to SSML's sophisticated voice language selection. This technical limitation may be
      alleviated in a future revision of the Speech module. </p>
    <dl>
      <dt>
        <strong>&lt;name&gt;</strong>
      </dt>
      <dd>
        <p>Values are specific voice instances (e.g., Mike, comedian, mary, carlos2, "valley girl").
          Voice names must either be given quoted as <a href="#strings-def">strings</a>, or unquoted
          as a sequence of one or more <a href="#identifier-def">identifiers</a>. </p>
        <p class="note">Note that as a result, most punctuation characters, or digits at the start
          of each token, must be escaped in unquoted voice names. </p>
        <p> If a sequence of identifiers is given as a voice name, the computed value is the name
          converted to a string by joining all the identifiers in the sequence by single spaces. </p>
        <p> Voice names that happen to be the same as the gender keywords ('male', 'female' and
          'neutral') or that happen to match the keywords 'inherit' or 'preserve' must be quoted to
          disambiguate with these keywords. The keywords 'initial' and 'default' are reserved for
          future use and must also be quoted when used as voice names. </p>
        <p class="note"> Note that in [[!SSML]], voice names are space-separated and cannot contain
          whitespace characters.</p>
        <p> It is recommended to quote voice names that contain white space, digits, or punctuation
          characters other than hyphens - even if these voice names are valid in unquoted form - in
          order to improve code clarity. For example: <code>voice-family: "john doe", "Henry
            the-8th";</code>
        </p>
      </dd>
      <dt>
        <strong>&lt;age&gt;</strong>
      </dt>
      <dd>
        <p> Possible values are 'child', 'young' and 'old', indicating the preferred age category to
          match during voice selection. </p>
        <p class="note"> Note that a recommended mapping with [[!SSML]] ages is: 'child' = 6 y/o,
          'young' = 24 y/o, 'old' = 75 y/o. More flexible age ranges may be used by the
          processor-dependent voice-matching algorithm. </p>
      </dd>
      <dt>
        <strong>&lt;gender&gt;</strong>
      </dt>
      <dd>
        <p> One of the keywords 'male', 'female', or 'neutral', specifying a male, female, or
          neutral voice, respectively. </p>
        <p class="note"> Note that the interpretation of the relationship between a person's age or
          gender, and a recognizable type of voice, cannot realistically be defined in a universal
          manner as it effectively depends on numerous criteria (cultural, linguistic, biological,
          etc.). The functionality provided by this specification therefore represent a simplified
          model that can be reasonably applied to a broad variety of speech contexts, albeit at the
          cost of a certain degree of approximation. Future versions of this specification may
          refine the level of precision of the voice-matching algorithm, as speech processor
          implementations become more standardized. </p>
      </dd>
      <dt>
        <strong>&lt;integer&gt;</strong>
      </dt>
      <dd>
        <p>An <a href="#integer-def">integer</a> indicating the preferred variant (e.g. "the second
          male child voice"). Only positive integers (i.e. excluding zero) are allowed. The value
          "1" refers to the first of all matching voices. </p>
      </dd>
      <dt>
        <strong>preserve</strong>
      </dt>
      <dd>
        <p>Indicates that the 'voice-family' value gets inherited and used regardless of any
          potential language change within the content markup (see the section below about voice
          selection and language handling). This value behaves as 'inherit' when applied to the root
          element. </p>
        <p class="note"> Note that descendants of the selected element automatically inherit the
          'preserve' value, unless it is explicitly overridden by other 'voice-family' values (e.g.
          name, gender, age). </p>
      </dd>
    </dl>
    <div class="example">
      <p> Examples of invalid declarations: </p>
      <pre>
voice-family: john/doe; /* forward slash character should be escaped */
voice-family: john "doe"; /* identifier sequence cannot contain strings */
voice-family: john!; /* exclamation mark should be escaped */
voice-family: john@doe; /* "at" character should be escaped */
voice-family: #john; /* identifier cannot start with hash character */
voice-family: john 1st; /* identifier cannot start with digit */</pre>
    </div>
    <h4 class="no-toc" id="voice-selection">Voice selection, content language</h4>
    <p>The 'voice-family' property is used to guide the selection of the speech synthesis voice
      instance. As part of this selection process, speech-capable user agents must also take into
      account the language of the selected element within the markup content. The "name", "gender",
      "age", and preferred "variant" (index) are voice selection hints that get carried down the
      content hierarchy as the 'voice-family' property value gets inherited by descendant elements.
      At any point within the content structure, the language takes precedence (i.e. has a higher
      priority) over the specified CSS voice characteristics. </p>
    <p> The following list outlines the voice selection algorithm (note that the definition of
      "language" is loose here, in order to cater for dialectic variations):</p>
    <ol>
      <li> If only a single voice instance is available for the language of the selected content,
        then this voice must be used, regardless of the specified CSS voice characteristics. </li>
      <li> If several voice instances are available for the language of the selected content, then
        the chosen voice is the one that most closely matches the specified name, or gender, age,
        and preferred voice variant. The actual definition of "best match" is processor-dependent.
        For example, in a system that only has male and female adult voices available, a reasonable
        match for "voice-family: young male" may well be a higher-pitched female voice, as this tone
        of voice would be close to that of a young boy. If no voice instance matches the
        characteristics provided by any of the 'voice-family' component values, the first available
        voice instance (amongst those suitable for the language of the selected content) must be
        used. </li>
      <li> If no voice is available for the language of the selected content, it is recommended that
        user agents let the user know about the lack of appropriate TTS voice. </li>
    </ol>
    <p>The speech synthesizer voice must be re-evaluated (i.e. the selection process must take place
      once again) whenever any of the CSS voice characteristics change within the content flow. The
      voice must also be re-calculated whenever the content language changes, unless the 'preserve'
      keyword is used (this may be useful in cases where embedded foreign language text can be
      spoken using a voice not designed for this language, as demonstrated by the example
      below).</p>
    <p class="note">Note that dynamically computing a voice may lead to unexpected lag, so user
      agents should try to resolve concrete voice instances in the document tree before the playback
      starts. </p>
    <div class="example">
      <p>Examples of property values:</p>
      <pre>
h1 { voice-family: announcer, old male; }
p.romeo  { voice-family: romeo, young male; }
p.juliet { voice-family: juliet, young female; }
p.mercutio { voice-family: young male; }
p.tybalt { voice-family: young male; }
p.nurse { voice-family: amelie; }

...

&lt;p class="romeo" xml:lang="en-US"&gt;
  The French text below will be spoken with an English voice:
  &lt;span style="voice-family: preserve;" xml:lang="fr-FR"&gt;Bonjour monsieur !&lt;/span&gt;

  The English text below will be spoken with a voice different
  than that corresponding to the class "romeo"
  (which is inherited from the "p" parent element):
  &lt;span style="voice-family: female;"&gt;Hello sir!&lt;/span&gt;
&lt;/p&gt;</pre>
    </div>
    <h3 id="voice-props-voice-rate">The 'voice-rate' property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="voice-rate">voice-rate</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>[normal | x-slow | slow | medium | fast | x-fast] || &lt;percentage&gt;</td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>normal</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>yes</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>refer to default value</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>a keyword value, and optionally also a percentage relative to the keyword (if not
            100%)</td>
        </tr>
      </tbody>
    </table>
    <p>The 'voice-rate' property manipulates the rate of generated synthetic speech in terms of
      words per minute.</p>
    <p class="note"> Note that although the functionality provided by this property is similar to
      the <a href="https://www.w3.org/TR/speech-synthesis11/#edef_prosody"><code>rate</code>
        attribute of the <code>prosody</code> element</a> from the SSML markup language [[!SSML]],
      there are notable discrepancies. For example, CSS Speech rate keywords and percentage
      modifiers are not mutually-exclusive, due to how values are inherited and combined for
      selected elements. </p>
    <dl>
      <dt>
        <strong>normal</strong>
      </dt>
      <dd>
        <p>Represents the default rate produced by the speech synthesizer for the currently active
          voice. This is processor-specific and depends on the language, dialect and on the
          "personality" of the voice. </p>
      </dd>
      <dt><strong>x-slow</strong>, <strong>slow</strong>, <strong>medium</strong>,
          <strong>fast</strong> and <strong>x-fast</strong></dt>
      <dd>
        <p>A sequence of monotonically non-decreasing speaking rates that are implementation and
          voice -specific. For example, typical values for the English language are (in words per
          minute) x-slow = 80, slow = 120, medium = between 180 and 200, fast = 500. </p>
      </dd>
      <dt>
        <strong>&lt;percentage&gt;</strong>
      </dt>
      <dd>
        <p>Only non-negative <a href="#percentage-def">percentage</a> values are allowed. This
          represents a change relative to the given keyword value (see enumeration above), or to the
          default value for the root element, or otherwise to the inherited speaking rate (which may
          itself be a combination of a keyword value and of a percentage, in which case percentages
          are combined multiplicatively). For example, 50% means that the speaking rate gets
          multiplied by 0.5 (half the value). Percentages above 100% result in faster speaking rates
          (relative to the base keyword), whereas percentages below 100% result in slower speaking
          rates.</p>
      </dd>
    </dl>
    <div class="example">
      <p>Examples of inherited values:</p>
      <pre>
&lt;body&gt;
  &lt;e1&gt;
    &lt;e2&gt;
      &lt;e3&gt;
        ...
      &lt;/e3&gt;
    &lt;/e2&gt;
  &lt;/e1&gt;
&lt;/body&gt;




body { voice-rate: inherit; } /* the initial value is 'normal'
                               (the actual speaking rate value
                               depends on the active voice) */

e1 { voice-rate: +50%; } /* the computed value is
                          ['normal' and 50%], which will resolve
                          to the rate corresponding to 'normal'
                          multiplied by 0.5 (half the speaking rate) */

e2 { voice-rate: fast 120%; } /* the computed value is
                          ['fast' and 120%], which will resolve
                          to the rate corresponding to 'fast'
                          multiplied by 1.2 */

e3 { voice-rate: normal; /* "resets" the speaking rate to the intrinsic voice value,
                            the computed value is 'normal' (see comment below for actual value) */

     voice-family: "another-voice"; } /* because the voice is different,
                                      the calculated speaking rate may vary
                                      compared to "body" (even though the computed
                                      'voice-rate' value is the same) */
      </pre>
    </div>
    <h3 id="voice-props-voice-pitch">The 'voice-pitch' property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="voice-pitch">voice-pitch</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;frequency&gt; &amp;&amp; absolute | [[x-low | low | medium | high | x-high] ||
            [&lt;frequency&gt; | &lt;semitones&gt; | &lt;percentage&gt;]] </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>medium</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>yes</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>refer to inherited value</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td> one of the predefined pitch keywords if only the keyword is specified by itself,
            otherwise an absolute frequency calculated by converting the keyword value (if any) to a
            fixed frequency based on the current voice-family and by applying the specified relative
            offset (if any)</td>
        </tr>
      </tbody>
    </table>
    <p>The 'voice-pitch' property specifies the "baseline" pitch of the generated speech output,
      which depends on the used 'voice-family' instance, and varies across speech synthesis
      processors (it approximately corresponds to the average pitch of the output). For example, the
      common pitch for a male voice is around 120Hz, whereas it is around 210Hz for a female
      voice.</p>
    <p class="note"> Note that although the functionality provided by this property is similar to
      the <a href="https://www.w3.org/TR/speech-synthesis11/#edef_prosody"><code>pitch</code>
        attribute of the <code>prosody</code> element</a> from the SSML markup language [[!SSML]],
      there are notable discrepancies. For example, CSS Speech pitch keywords and relative changes
      (frequency, semitone or percentage) are not mutually-exclusive, due to how values are
      inherited and combined for selected elements. </p>
    <dl>
      <dt>
        <strong>&lt;frequency&gt;</strong>
      </dt>
      <dd>
        <p> A value in <a href="#frequency-def">frequency</a> units (Hertz or kiloHertz, e.g.
          "100Hz", "+2kHz"). Values are restricted to positive numbers when the 'absolute' keyword
          is specified. Otherwise (when the 'absolute' keyword is not specified), a negative value
          represents a decrement, and a positive value represents an increment, relative to the
          inherited value. For example, "2kHz" is a positive offset (strictly equivalent to
          "+2kHz"), and "+2kHz absolute" is an absolute frequency (strictly equivalent to "2kHz
          absolute"). </p>
      </dd>
      <dt>
        <strong>absolute</strong>
      </dt>
      <dd>
        <p> If specified, this keyword indicates that the specified frequency represents an absolute
          value. If a negative frequency is specified, the computed frequency will be zero. </p>
      </dd>
      <dt>
        <strong>&lt;semitones&gt;</strong>
      </dt>
      <dd>
        <p> Specifies a relative change (decrement or increment) to the inherited value. The syntax
          of allowed values is a &lt;<a href="#number-def">number</a>&gt; followed immediately by
          "st" (semitones). A semitone interval corresponds to the step between each note on an
          equal temperament chromatic scale. A semitone can therefore be quantified as the
          difference between two consecutive pitch frequencies on such scale. The ratio between two
          consecutive frequencies separated by exactly one semitone is the twelfth root of two
          (approximately 11011/10393, which equals exactly 1.0594631). As a result, the value in
          Hertz corresponding to a semitone offset is relative to the initial frequency the offset
          is applied to (in other words, a semitone doesn't correspond to a fixed numerical value in
          Hertz). </p>
      </dd>
      <dt>
        <strong>&lt;percentage&gt;</strong>
      </dt>
      <dd>
        <p> Positive and negative <a href="#percentage-def">percentage</a> values are allowed, to
          represent an increment or decrement (respectively) relative to the inherited value.
          Computed values are calculated by adding (or subtracting) the specified fraction of the
          inherited value, to (from) the inherited value. For example, 50% (which is equivalent to
          +50%) with a inherited value of 200Hz results in <code>200 + (200*0.5)</code> = 300Hz.
          Conversely, -50% results in <code>200-(200*0.5)</code> = 100Hz. </p>
      </dd>
      <dt><strong>x-low</strong>, <strong>low</strong>, <strong>medium</strong>,
          <strong>high</strong>, <strong>x-high</strong></dt>
      <dd>
        <p>A sequence of monotonically non-decreasing pitch levels that are implementation and voice
          specific. When the computed value for a given element is only a keyword (i.e. no relative
          offset is specified), then the corresponding absolute frequency will be re-evaluated on a
          voice change. Conversely, the application of a relative offset requires the calculation of
          the resulting frequency based on the current voice at the point at which the relative
          offset is specified, so the computed frequency will inherit absolutely regardless of any
          voice change further down the style cascade. Authors should therefore only use keyword
          values in cases where they wish that voice changes trigger the re-evaluation of the
          conversion from a keyword to a concrete, voice-dependent frequency.</p>
      </dd>
    </dl>
    <p> Computed absolute frequencies that are negative are clamped to zero Hertz. Speech-capable
      user agents are likely to support a specific range of values rather than the full range of
      possible calculated numerical values for frequencies. The actual values in user agents may
      therefore be clamped to implementation-dependent minimum and maximum boundaries. For example:
      although the 0Hz frequency can be legitimately calculated, it may be clamped to a more
      meaningful value in the context of the speech synthesizer. </p>
    <div class="example">
      <p>Examples of property values:</p>
      <pre>
h1 { voice-pitch: 250Hz; } /* positive offset relative to the inherited absolute frequency */
h1 { voice-pitch: +250Hz; } /* identical to the line above */
h2 { voice-pitch: +30Hz absolute; } /* not an increment */
h2 { voice-pitch: absolute 30Hz; } /* identical to the line above */
h3 { voice-pitch: -20Hz; } /* negative offset (decrement) relative to the inherited absolute frequency */
h4 { voice-pitch: -20Hz absolute; } /* illegal syntax => value ignored ("absolute" keyword not allowed with negative frequency) */
h5 { voice-pitch: -3.5st; } /* semitones, negative offset */
h6 { voice-pitch: 25%; } /* this means "add a quarter of the inherited value, to the inherited value" */
h6 { voice-pitch: +25%; } /* identical to the line above */
      </pre>
    </div>
    <h3 id="voice-props-voice-range">The 'voice-range' property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="voice-range">voice-range</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>&lt;frequency&gt; &amp;&amp; absolute | [[x-low | low | medium | high | x-high] ||
            [&lt;frequency&gt; | &lt;semitones&gt; | &lt;percentage&gt;]] </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>medium</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>yes</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>refer to inherited value</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td> one of the predefined pitch keywords if only the keyword is specified by itself,
            otherwise an absolute frequency calculated by converting the keyword value (if any) to a
            fixed frequency based on the current voice-family and by applying the specified relative
            offset (if any)</td>
        </tr>
      </tbody>
    </table>
    <p> The 'voice-range' property specifies the variability in the "baseline" pitch, i.e. how much
      the fundamental frequency may deviate from the average pitch of the speech output. The dynamic
      pitch range of the generated speech generally increases for a highly animated voice, for
      example when variations in inflection are used to convey meaning and emphasis in speech.
      Typically, a low range produces a flat, monotonic voice, whereas a high range produces an
      animated voice. </p>
    <p class="note"> Note that although the functionality provided by this property is similar to
      the <a href="https://www.w3.org/TR/speech-synthesis11/#edef_prosody"><code>range</code>
        attribute of the <code>prosody</code> element</a> from the SSML markup language [[!SSML]],
      there are notable discrepancies. For example, CSS Speech pitch range keywords and relative
      changes (frequency, semitone or percentage) are not mutually-exclusive, due to how values are
      inherited and combined for selected elements. </p>
    <dl>
      <dt>
        <strong>&lt;frequency&gt;</strong>
      </dt>
      <dd>
        <p> A value in <a href="#frequency-def">frequency</a> units (Hertz or kiloHertz, e.g.
          "100Hz", "+2kHz"). Values are restricted to positive numbers when the 'absolute' keyword
          is specified. Otherwise (when the 'absolute' keyword is not specified), a negative value
          represents a decrement, and a positive value represents an increment, relative to the
          inherited value. For example, "2kHz" is a positive offset (strictly equivalent to
          "+2kHz"), and "+2kHz absolute" is an absolute frequency (strictly equivalent to "2kHz
          absolute"). </p>
      </dd>
      <dt>
        <strong>absolute</strong>
      </dt>
      <dd>
        <p> If specified, this keyword indicates that the specified frequency represents an absolute
          value. If a negative frequency is specified, the computed frequency will be zero. </p>
      </dd>
      <dt>
        <strong>&lt;semitones&gt;</strong>
      </dt>
      <dd>
        <p> Specifies a relative change (decrement or increment) to the inherited value. The syntax
          of allowed values is a &lt;<a href="#number-def">number</a>&gt; followed immediately by
          "st" (semitones). A semitone interval corresponds to the step between each note on an
          equal temperament chromatic scale. A semitone can therefore be quantified as the
          difference between two consecutive pitch frequencies on such scale. The ratio between two
          consecutive frequencies separated by exactly one semitone is the twelfth root of two
          (approximately 11011/10393, which equals exactly 1.0594631). As a result, the value in
          Hertz corresponding to a semitone offset is relative to the initial frequency the offset
          is applied to (in other words, a semitone doesn't correspond to a fixed numerical value in
          Hertz).</p>
      </dd>
      <dt>
        <strong>&lt;percentage&gt;</strong>
      </dt>
      <dd>
        <p> Positive and negative <a href="#percentage-def">percentage</a> values are allowed, to
          represent an increment or decrement (respectively) relative to the inherited value.
          Computed values are calculated by adding (or subtracting) the specified fraction of the
          inherited value, to (from) the inherited value. For example, 50% (which is equivalent to
          +50%) with a inherited value of 200Hz results in <code>200 + (200*0.5)</code> = 300Hz.
          Conversely, -50% results in <code>200-(200*0.5)</code> = 100Hz. </p>
      </dd>
      <dt><strong>x-low</strong>, <strong>low</strong>, <strong>medium</strong>,
          <strong>high</strong>, <strong>x-high</strong></dt>
      <dd>
        <p>A sequence of monotonically non-decreasing pitch levels that are implementation and voice
          specific. When the computed value for a given element is only a keyword (i.e. no relative
          offset is specified), then the corresponding absolute frequency will be re-evaluated on a
          voice change. Conversely, the application of a relative offset requires the calculation of
          the resulting frequency based on the current voice at the point at which the relative
          offset is specified, so the computed frequency will inherit absolutely regardless of any
          voice change further down the style cascade. Authors should therefore only use keyword
          values in cases where they wish that voice changes trigger the re-evaluation of the
          conversion from a keyword to a concrete, voice-dependent frequency.</p>
      </dd>
    </dl>
    <p> Computed absolute frequencies that are negative are clamped to zero Hertz. Speech-capable
      user agents are likely to support a specific range of values rather than the full range of
      possible calculated numerical values for frequencies. The actual values in user agents may
      therefore be clamped to implementation-dependent minimum and maximum boundaries. For example:
      although the 0Hz frequency can be legitimately calculated, it may be clamped to a more
      meaningful value in the context of the speech synthesizer. </p>
    <div class="example">
      <p>Examples of inherited values:</p>
      <pre>
&lt;body&gt;
  &lt;e1&gt;
    &lt;e2&gt;
      &lt;e3&gt;
        &lt;e4&gt;
          &lt;e5&gt;
            &lt;e6&gt;
            ...
            &lt;/e6&gt;
          &lt;/e5&gt;
        &lt;/e4&gt;
      &lt;/e3&gt;
    &lt;/e2&gt;
  &lt;/e1&gt;
&lt;/body&gt;




body { voice-range: inherit; } /* the initial value is 'medium'
                               (the actual frequency value
                               depends on the current voice) */

e1 { voice-range: +25%; } /* the computed value is
                          ['medium' + 25%] which resolves
                          to the frequency corresponding to 'medium'
                          plus 0.25 times the frequency
                          corresponding to 'medium' */

e2 { voice-range: +10Hz; } /* the computed value is
                          [FREQ + 10Hz] where "FREQ" is the absolute frequency
                          calculated in the "e1" rule above.
                          */

e3 { voice-range: inherit; /* this could be omitted,
                           but we explicitly specify it for clarity purposes */

     voice-family: "another-voice"; } /* this voice change would have resulted in
                              the re-evaluation of the initial 'medium' keyword
                              inherited by the "body" element
                              (i.e. conversion from a voice-dependent keyword value
                              to a concrete, absolute frequency),
                              but because relative offsets were applied down the style
                              cascade, the inherited value is actually the frequency
                              calculated at the "e2" rule above. */

e4 { voice-range: 200Hz absolute; } /* override with an absolute frequency
                                    which doesn't depend on the current voice */

e5 { voice-range: 2st; } /* the computed value is an absolute frequency,
                         which is the result of the
                         calculation: 200Hz + two semitones
                         (reminder: the actual frequency corresponding to a semitone
                         depends on the base value to which it applies) */

e6 { voice-range: inherit; /* this could be omitted,
                           but we explicitly specify it for clarity purposes */

     voice-family: "yet-another-voice"; } /* despite the voice change,
                              the computed value is the same as
                              for "e5" (i.e. an absolute frequency value,
                              independent from the current voice) */
      </pre>
    </div>
    <h3 id="voice-props-voice-stress">The 'voice-stress' property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="voice-stress">voice-stress</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>normal | strong | moderate | none | reduced </td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>normal</td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>yes</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>specified value</td>
        </tr>
      </tbody>
    </table>
    <p>The 'voice-stress' property manipulates the strength of emphasis, which is normally applied
      using a combination of pitch change, timing changes, loudness and other acoustic differences.
      The precise meaning of the values therefore depend on the language being spoken. </p>
    <p class="note"> Note that the functionality provided by this property is similar to the <a
        href="https://www.w3.org/TR/speech-synthesis11/#edef_emphasis"><code>emphasis</code>
        element</a> from the SSML markup language [[!SSML]]. </p>
    <dl>
      <dt>
        <strong>normal</strong>
      </dt>
      <dd>
        <p>Represents the default emphasis produced by the speech synthesizer.</p>
      </dd>
      <dt>
        <strong>none</strong>
      </dt>
      <dd>
        <p>Prevents the synthesizer from emphasizing text it would normally emphasize.</p>
      </dd>
      <dt><strong>moderate</strong> and <strong>strong</strong></dt>
      <dd>
        <p>These values are monotonically non-decreasing in strength. Their application results in
          more emphasis than what the speech synthesizer would normally produce (i.e. more than the
          value corresponding to 'normal'). </p>
      </dd>
      <dt>
        <strong>reduced</strong>
      </dt>
      <dd>
        <p>Effectively the opposite of emphasizing a word.</p>
      </dd>
    </dl>
    <div class="example">
      <p>Examples of property values, with HTML sample:</p>
      <pre>
.default-emphasis { voice-stress: normal; }
.lowered-emphasis { voice-stress: reduced; }
.removed-emphasis { voice-stress: none; }
.normal-emphasis { voice-stress: moderate; }
.huge-emphasis { voice-stress: strong; }

...

&lt;p&gt;This is a big car.&lt;/p&gt;
&lt;!-- The speech output from the line above is identical to the line below: --&gt;
&lt;p&gt;This is a &lt;em class="default-emphasis"&gt;big&lt;/em&gt; car.&lt;/p&gt;

&lt;p&gt;This car is &lt;em class="lowered-emphasis"&gt;massive&lt;/em&gt;!&lt;/p&gt;
&lt;!-- The "em" below is totally de-emphasized, whereas the emphasis in the line above is only reduced: --&gt;
&lt;p&gt;This car is &lt;em class="removed-emphasis"&gt;massive&lt;/em&gt;!&lt;/p&gt;

&lt;!-- The lines below demonstrate increasing levels of emphasis: --&gt;
&lt;p&gt;This is a &lt;em class="normal-emphasis"&gt;big&lt;/em&gt; car!&lt;/p&gt;
&lt;p&gt;This is a &lt;em class="huge-emphasis"&gt;big&lt;/em&gt; car!!!&lt;/p&gt;</pre>
    </div>
    <h2 id="duration-props">Voice duration property</h2>
    <h3 id="mixing-props-voice-duration">The 'voice-duration' property</h3>
    <table class="propdef" summary="name: syntax">
      <tbody>
        <tr>
          <td>Name:</td>
          <td>
            <dfn id="voice-duration">voice-duration</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <em>Value:</em>
          </td>
          <td>auto | &lt;time&gt;</td>
        </tr>
        <tr>
          <td>
            <em>Initial:</em>
          </td>
          <td>
            <em>auto</em>
          </td>
        </tr>
        <tr>
          <td>
            <em>Applies&nbsp;to:</em>
          </td>
          <td>all elements</td>
        </tr>
        <tr>
          <td>
            <em>Inherited:</em>
          </td>
          <td>no</td>
        </tr>
        <tr>
          <td>
            <em>Percentages:</em>
          </td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>
            <em>Computed value:</em>
          </td>
          <td>specified value</td>
        </tr>
      </tbody>
    </table>
    <p> The 'voice-duration' property specifies how long it should take to render the selected
      element's content (not including <a href="#cue-props">audio cues</a>, <a href="#pause-props">
        pauses</a> and <a href="#rest-props">rests</a> ). Unless the value 'auto' is specified, this
      property takes precedence over the 'voice-rate' property, and should be used to determine a
      suitable speaking rate for the voice. An element for which the 'voice-duration' property value
      is not 'auto' may have descendants for which the 'voice-duration' and 'voice-rate' properties
      are specified, but these must be ignored. In other words, when a 'time' is specified for the
      'voice-duration' of a selected element, it applies to the entire element subtree (children
      cannot override the property). </p>
    <p class="note"> Note that the functionality provided by this property is similar to the <a
        href="https://www.w3.org/TR/speech-synthesis11/#edef_prosody"><code>duration</code> attribute
        of the <code>prosody</code> element</a> from the SSML markup language [[!SSML]]. </p>
    <dl>
      <dt>
        <strong>auto</strong>
      </dt>
      <dd>
        <p>Resolves to a used value corresponding to the duration of the speech synthesis when using
          the inherited 'voice-rate'. </p>
      </dd>
      <dt>
        <strong>&lt;time&gt;</strong>
      </dt>
      <dd>
        <p> Specifies a value in absolute <a href="#time-def">time</a> units (seconds and
          milliseconds, e.g. "+3s", "250ms"). Only non-negative values are allowed. </p>
      </dd>
    </dl>
    <h2 id="lists">List items and counters styles</h2>
    <p>The '<a href="#list-style-type-def">
        <code class="property">list-style-type</code></a>' property of [[!CSS21]] specifies three
      types of list item markers: glyphs, numbering systems, and alphabetic systems. The values
      allowed for this property are also used for the counter() function of the 'content' property.
      The CSS Speech module defines how to render these styles in the aural dimension, using speech
      synthesis. The '<a href="#list-style-image-def"><code class="property"
        >list-style-image</code></a>' property of [[!CSS21]] is ignored, and instead the '<a
        href="#list-style-type-def"><code class="property">list-style-type</code></a>' is used. </p>
    <p class="note"> Note that the speech rendering of new features from the CSS Lists and Counters
      Module Level 3 [[CSS3LIST]] is not covered in this level of CSS Speech, but may be defined in
      a future specification.</p>
    <dl>
      <dt>
        <strong>disc, circle, square</strong>
      </dt>
      <dd>
        <p> For these list item styles, the user agent defines (possibly based on user preferences)
          what equivalent phrase is spoken or what audio cue is played. List items with graphical
          bullets are therefore announced appropriately in an implementation-dependent manner. </p>
      </dd>
      <dt>
        <strong>decimal, decimal-leading-zero, lower-roman, upper-roman, georgian, armenian</strong>
      </dt>
      <dd>
        <p> For these list item styles, corresponding numbers are spoken as-is by the speech
          synthesizer, and may be complemented with additional audio cues or speech phrases in the
          document's language (i.e. with the same TTS voice used to speak the list item content) in
          order to indicate the presence of list items. For example, when using the English
          language, the list item counter could be prefixed with the word "Item", which would result
          in list items being announced with "Item one", "Item two", etc. </p>
      </dd>
      <dt>
        <strong>lower-latin, lower-alpha, upper-latin, upper-alpha, lower-greek</strong>
      </dt>
      <dd>
        <p> These list item styles are spelled out letter-by-letter by the speech synthesizer, in
          the document language (i.e. with the same TTS voice used to speak the list item content).
          For example, 'lower-greek' in English would be read out as "alpha", "beta", "gamma", etc.
          Conversely, 'upper-latin' in French would be read out as /a/, /be/, /se/, etc. (phonetic
          notation) </p>
      </dd>
    </dl>
    <p class="note">Note that it is common for user agents such as screen readers to announce the
      nesting depth of list items, or more generally, to indicate additional structural information
      pertaining to complex hierarchical content. The verbosity of these additional audio cues
      and/or speech output can usually be controlled by users, and contribute to increasing
      usability. These navigation aids are implementation-dependent, but it is recommended that user
      agents supporting the CSS Speech module ensure that these additional audio cues and speech
      output don't generate redundancies or create inconsistencies (for example: duplicated or
      different list item numbering scheme). </p>
    <h2 id="content">Inserted and replaced content</h2>
    <p class="note">Note that this entire section is informative.</p>
    <p>Sometimes, authors will want to specify a mapping from the source text into another string
      prior to the application of the regular pronunciation rules. This may be used for uncommon
      abbreviations or acronyms which are unlikely to be recognized by the synthesizer. The
      'content' property can be used to replace one string by another. The functionality provided by
      this property is similar to the <a href="https://www.w3.org/TR/speech-synthesis11/#edef_sub"
          ><code>alias</code> attribute of the <code>sub</code> element</a> from the SSML markup
      language [[!SSML]]. </p>
    <div class="example">
      <p> In this example, the abbreviation is rendered using the content of the title attribute
        instead of the element's content.</p>
      <pre>
/* This replaces the content of the selected element
by the string "World Wide Web Consortium". */
abbr { content: attr(title); }
...

&lt;abbr title="World Wide Web Consortium"&gt;W3C&lt;/abbr&gt;</pre>
    </div>
    <p>In a similar way, text strings in a document can be replaced by a previously recorded
      version.</p>
    <div class="example">
      <p>In this example - assuming the format is supported, the file is available and the UA is
        configured to do so - a recording of Sir John Gielgud's declamation of the famous monologue
        is played. Otherwise the UA falls back to render the text using synthesized speech. </p>
      <pre>
.hamlet { content: url(./audio/gielgud.wav); }
...

&lt;div class="hamlet"&gt;
To be, or not to be: that is the question:
&lt;/div&gt;</pre>
    </div>
    <p>Furthermore, authors (or users via a user stylesheet) may add some information to ease the
      understanding of structures during non-visual interaction with the document. They can do so by
      using the '::before' and '::after' pseudo-elements. Note that different stylesheets can be
      used to define the level of verbosity for additional information spoken by screen readers.</p>
    <div class="example">
      <p>This example inserts the string "Start list: " before a list and the string "List item: "
        before the content of each list item. Likewise, the string "List end: " gets inserted after
        the list to inform the user that the list speech output is over.</p>
      <pre>
ul::before { content: "Start list: "; }
ul::after  { content: "List end. "; }
li::before { content: "List item: "; }</pre>
    </div>
    <p>Detailed information can be found in the CSS3 Generated and Replaced Content module
      [[CSS3GENCON]].</p>
    <h2 id="pronunciation"> Pronunciation, phonemes </h2>
    <p class="note">Note that this entire section is informative.</p>
    <p> CSS does not specify how to define the pronunciation (expressed using a well-defined
      phonetic alphabet) of a particular piece of text within the markup document. A "phonemes"
      property was described in earlier drafts of this specification, but objections were raised due
      to breaking the principle of separation between content and presentation (the "phonemes"
      authored within aural CSS stylesheets would have needed to be updated each time text changed
      within the markup document). The "phonemes" functionality is therefore considered out-of-scope
      in CSS (the presentation layer) and should be addressed in the markup / content layer.</p>
    <p> The <a href="http://microformats.org/wiki/rel-pronunciation">"pronunciation"</a>
      <code>rel</code> value allows importing pronunciation lexicons in HTML documents using the
        <code>link</code> element (similar to how CSS stylesheets can be included). The W3C PLS
      (Pronunciation Lexicon Specification) [[PRONUNCIATION-LEXICON]] is one format that can be used
      to describe such a lexicon.</p>
    <p> Additionally, an attribute-based mechanism can be used within the markup to author
      text-pronunciation associations. At the time of writing, such mechanism isn't formally defined
      in the W3C HTML standard(s). However, the <a href="http://idpf.org/epub/30">EPUB 3.0
        specification</a> allows (x)HTML5 documents to contain attributes derived from the [[!SSML]]
      specification, that describe how to pronounce text based on a particular phonetic
      alphabet.</p>
    <!-- p>
      One avenue to explore is the use CSS to "bind" HTML text with a
      phoneme (also declared in the HTML document). This would maintain a
      clear separation between content and presentation, and it would allow
      authors to define different pronunciations for one given text token
      (Media Queries could drive the switch of stylesheet to import). This
      possibility has been mentioned several times by Working Group members
      as well as people from the public mailing-list, so it cannot be
      ignored. However, there are architectural considerations (e.g.
      collision between CSS versus HTML -defined phonemes) which make this a
      lot trickier to standardize than it sounds. The
      whole "speech synthesis" issue should be tackled globally at the level
      of the W3C ecosystem. For example, there are many cross-cutting
      concerns with the work done by the HTML-Audio and HTML-Speech
      Incubator Groups.
      </p -->
    <h2 class="no-num" id="property-index">Appendix A &mdash; Property index</h2>
    <!-- properties -->
    <p>The following properties are defined in other modules or specifications:</p>
    <ul>
      <li>
        <dfn id="display-def">
          <a href="https://www.w3.org/TR/CSS21/visuren.html#display-prop"> display </a></dfn>
        &nbsp;&nbsp; [[!CSS21]] </li>
      <li>
        <dfn id="padding-def">
          <a href="https://www.w3.org/TR/CSS21/box.html#padding-properties"> padding </a></dfn>
        &nbsp;&nbsp; [[!CSS21]] </li>
      <li>
        <dfn id="border-def">
          <a href="https://www.w3.org/TR/CSS21/box.html#border-properties"> border </a></dfn>
        &nbsp;&nbsp; [[!CSS21]] </li>
      <li>
        <dfn id="margin-def">
          <a href="https://www.w3.org/TR/CSS21/box.html#margin-properties"> margin </a></dfn>
        &nbsp;&nbsp; [[!CSS21]] </li>
      <li>
        <dfn id="font-family-def">
          <a href="https://www.w3.org/TR/CSS21/fonts.html#font-family-prop"> font-family </a></dfn>
        &nbsp;&nbsp; [[!CSS21]] </li>
      <li><dfn id="content-def">content</dfn> &nbsp;&nbsp; [[CSS3GENCON]]</li>
      <li>
        <dfn id="list-style-type-def">
          <a href="https://www.w3.org/TR/CSS21/generate.html#propdef-list-style-type">
            list-style-type </a></dfn> &nbsp;&nbsp; [[!CSS21]] </li>
      <li>
        <dfn id="list-style-image-def">
          <a href="https://www.w3.org/TR/CSS21/generate.html#propdef-list-style-image">
            list-style-image </a></dfn> &nbsp;&nbsp; [[!CSS21]] </li>
    </ul>
    <p>The following definitions are provided by other modules or specifications:</p>
    <ul>
      <li>
        <dfn id="cascade-def">
          <a href="https://www.w3.org/TR/CSS21/cascade.html#cascade"> cascade </a></dfn> &nbsp;&nbsp;
        [[!CSS21]] </li>
      <li>
        <dfn id="box-model-def">
          <a href="https://www.w3.org/TR/CSS21/box.html"> visual box model </a></dfn> &nbsp;&nbsp;
        [[!CSS21]] </li>
      <li>
        <dfn id="time-def">
          <a href="https://www.w3.org/TR/css3-values/#time"> time </a></dfn> &nbsp;&nbsp;
        [[!CSS3VAL]] </li>
      <li>
        <dfn id="frequency-def">
          <a href="https://www.w3.org/TR/css3-values/#frequency"> frequency </a></dfn> &nbsp;&nbsp;
        [[!CSS3VAL]] </li>
      <li>
        <dfn id="number-def">
          <a href="https://www.w3.org/TR/css3-values/#numbers"> number </a></dfn> &nbsp;&nbsp;
        [[!CSS3VAL]] </li>
      <li>
        <dfn id="integer-def">
          <a href="https://www.w3.org/TR/css3-values/#integers"> integer </a></dfn> &nbsp;&nbsp;
        [[!CSS3VAL]] </li>
      <li>
        <dfn id="non-negative-number-def">
          <a href="https://www.w3.org/TR/css3-values/#numbers"> non-negative-number </a></dfn>
        &nbsp;&nbsp; [[!CSS3VAL]] </li>
      <li>
        <dfn id="percentage-def">
          <a href="https://www.w3.org/TR/css3-values/#percentages"> percentage </a></dfn>
        &nbsp;&nbsp; [[!CSS3VAL]] </li>
      <li>
        <dfn id="identifier-def">
          <a href="https://www.w3.org/TR/CSS21/syndata.html#value-def-identifier"> identifier
          </a></dfn> &nbsp;&nbsp; [[!CSS21]] </li>
      <li>
        <dfn id="strings-def">
          <a href="https://www.w3.org/TR/CSS21/syndata.html#strings"> strings </a></dfn> &nbsp;&nbsp;
        [[!CSS21]] </li>
    </ul>
    <h2 class="no-num" id="index">Appendix B &mdash; Index</h2>
    <!--index-->
    <h2 class="no-num" id="definitions">Appendix C &mdash; Definitions</h2>
    <h3 class="no-num" id="glossary">Glossary</h3>
    <p>The following terms and abbreviations are used in this module.</p>
    <dl>
      <dt>
        <dfn>UA</dfn>
      </dt>
      <dt>
        <dfn id="user-agent">User Agent</dfn>
      </dt>
      <dd>
        <p>A program that reads and/or writes CSS style sheets on behalf of a user in either or both
          of these categories: programs whose purpose is to render <span>documents</span> (e.g.,
          browsers) and programs whose purpose is to create style sheets (e.g., editors). A UA may
          fall into both categories. (There are other programs that read or write style sheets, but
          this module gives no rules for them.) </p>
      </dd>
      <dt>
        <dfn title="document|documents">document</dfn>
      </dt>
      <dd>
        <p>A tree-structured document with elements and attributes, such as an SGML or XML document
          [[!XML11]]. </p>
      </dd>
      <dt>
        <dfn>style sheet</dfn>
      </dt>
      <dd>
        <p>A <a href="https://www.w3.org/TR/CSS21/conform.html#style-sheet">CSS style sheet</a></p>
      </dd>
    </dl>
    <h3 class="no-num" id="conformance">Conformance</h3>
    <p>Conformance requirements are expressed with a combination of descriptive assertions and RFC
      2119 terminology. The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
      "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in the normative parts of this
      document are to be interpreted as described in RFC 2119. However, for readability, these words
      do not appear in all uppercase letters in this specification. All of the text of this
      specification is normative except sections explicitly marked as non-normative, examples, and
      notes. [[!RFC2119]]</p>
    <p>Examples in this specification are introduced with the words "for example" or are set apart
      from the normative text with <code>class="example"</code>, like this: </p>
    <div class="example">
      <p>This is an example of an informative example.</p>
    </div>
    <p>Informative notes begin with the word "Note" and are set apart from the normative text with
        <code>class="note"</code>, like this:</p>
    <p class="note">Note, this is an informative note.</p>
    <p>Conformance to the CSS3 Speech module is defined for three classes:</p>
    <dl>
      <dt>
        <dfn title="style sheet!!as conformance class">style sheet</dfn>
      </dt>
      <dd>A <a href="https://www.w3.org/TR/CSS21/conform.html#style-sheet">CSS style sheet</a>.</dd>
      <dt>
        <dfn>renderer</dfn>
      </dt>
      <dd>A UA that interprets the semantics of a style sheet and renders <span>documents</span>
        that use them.</dd>
      <dt>
        <dfn id="authoring-tool">authoring tool</dfn>
      </dt>
      <dd>A UA that writes a style sheet.</dd>
    </dl>
    <p>A style sheet is conformant to the CSS3 Speech module if all of its declarations that use
      properties defined in this module have values that are valid according to the generic CSS
      grammar and the individual grammars of each property as given in this module. </p>
    <p>A renderer is conformant to the CSS3 Speech module if, in addition to interpreting the style
      sheet as defined by the appropriate specifications, it supports all the properties defined by
      CSS3 Speech module by parsing them correctly and rendering the document accordingly. However
      the inability of a UA to correctly render a document due to limitations of the device does not
      make the UA non-conformant. (For example, a UA is not required to render color on a monochrome
      monitor.) </p>
    <p>An authoring tool is conformant to CSS3 Speech module if it writes syntactically correct
      style sheets, according to the generic CSS grammar and the individual grammars of each
      property in this module. </p>
    <!-- h3 class="no-num" id="levels">Levels</h3>

            <p><em>This section is informative.</em> CSS has different levels of
            features, each a subset of the other. (See [[CSSBEIJING]] for a full
            explanation.) The lists below describe which features from this
            specification are in each level.

            <h4 class="no-num" id="level-1">CSS Level 1</h4>
            <ul>
            <li>'background-color'
            <li>'background-image' only one image (no layers)
            <li>'background-repeat': only 'repeat' | 'repeat-x' | 'repeat-y' | 'no-repeat'
            <li>'background-attachment': only 'scroll' | 'fixed'
            <li>'background-position': only one or two values allowed
            <li>'background' shorthand: only color, image, repeat, attachment and position
            <li>'border-color' properties
            <li>'border-style' properties
            <li>'border-width' properties
            <li>'border-top', 'border-bottom', 'border-right', 'border-left', and 'border' shorthands
            </ul>

            <h4 class="no-num" id="level-2">CSS Level 2</h4>
            <ul>
            <li>'background-color'
            <li>'background-image': only one image (no layers)
            <li>'background-repeat': only 'repeat' | 'repeat-x' | 'repeat-y' | 'no-repeat'
            <li>'background-attachment': only 'scroll' | 'fixed'
            <li>'background-position': only one or two values allowed
            <li>'background': only color, image, repeat, attachment and position
            <li>'border-color' properties
            <li>'border-style' properties
            <li>'border-width' properties
            <li>'border-top', 'border-bottom', 'border-right', 'border-left', and 'border' shorthands
            </ul>

            <h4 class="no-num" id="level-3">CSS Level 3</h4>
            <ul>
            <li>All features described in the CSS3 Speech module
            </ul -->
    <h3 class="no-num" id="exit">CR exit criteria</h3>
    <p>As described in the W3C process document, a <a
        href="http://www.w3.org/2005/10/Process-20051014/tr.html#cfi">Candidate Recommendation</a>
      (CR) is a specification that W3C recommends for use on the Web. The next stage is
      "Recommendation" when the specification is sufficiently implemented.</p>
    <p>For this specification to be proposed as a W3C Recommendation, the following conditions shall
      be met. There must be at least two independent, interoperable implementations of each feature.
      Each feature may be implemented by a different set of products, there is no requirement that
      all features be implemented by a single product. For the purposes of this criterion, we define
      the following terms: </p>
    <dl>
      <dt>independent</dt>
      <dd>each implementation must be developed by a different party and cannot share, reuse, or
        derive from code used by another qualifying implementation. Sections of code that have no
        bearing on the implementation of this specification are exempt from this requirement.</dd>
      <dt>interoperable</dt>
      <dd>passing the respective test case(s) in the official CSS test suite, or, if the
        implementation is not a Web browser, an equivalent test. Every relevant test in the test
        suite should have an equivalent test created if such a user agent (UA) is to be used to
        claim interoperability. In addition if such a UA is to be used to claim interoperability,
        then there must one or more additional UAs which can also pass those equivalent tests in the
        same way for the purpose of interoperability. The equivalent tests must be made publicly
        available for the purposes of peer review.</dd>
      <dt>implementation</dt>
      <dd>a user agent which: <ol class="inline">
          <li>implements the specification.</li>
          <li>is available to the general public. The implementation may be a shipping product or
            other publicly available version (i.e., beta version, preview release, or "nightly
            build"). Non-shipping product releases must have implemented the feature(s) for a period
            of at least one month in order to demonstrate stability.</li>
          <li>is not experimental (i.e., a version specifically designed to pass the test suite and
            is not intended for normal usage going forward).</li>
        </ol>
      </dd>
    </dl>
    <p>A minimum of sixth months of the CR period must have elapsed. This is to ensure that enough
      time is given for any remaining major errors to be caught. </p>
    <p>Features will be dropped if two or more interoperable implementations are not found by the
      end of the CR period. </p>
    <p>Features may/will also be dropped if adequate/sufficient (by judgment of CSS WG) tests have
      not been produced for those feature(s) by the end of the CR period. </p>
    <h2 class="no-num" id="ack">Appendix D &mdash; Acknowledgements</h2>
    <p>The editors would like to thank the members of the W3C Voice Browser and Cascading Style
      Sheets working groups for their assistance in preparing this specification. Special thanks to
      Ellen Eide (IBM) for her detailed comments, and to Elika Etemad (Fantasai) for her thorough
      reviews.</p>
    <h2 class="no-num" id="changes">Appendix E &mdash; Changes</h2>
    The following changes have been made since the <a href="https://www.w3.org/TR/2012/CR-css3-speech-20120320/">2012 Candidate Recommendation</a>:

    <ul>
      <li>Renamed the ''none'' and ''normal'' values of 'speak' to ''never'' and ''always'' for clarity.
      See <a href="https://github.com/w3c/csswg-drafts/issues/510">Issue 510</a>.
      <li>Made the ''auto'' value of 'speak' respond to 'visibility'.
      See <a href="https://github.com/w3c/csswg-drafts/issues/511">Issue 511</a>.
	</ul>

    <h2 class="no-num" id="references">Appendix F &mdash; References</h2>
    <h3 class="no-num">Normative references</h3>
    <!--normative-->
    <h3 class="no-num">Other references</h3>
    <!--informative-->
  </body>
</html>
<!-- Keep this comment at the end of the file
    Local variables:
    mode: sgml
    sgml-default-doctype-name:"html"
    sgml-minimize-attributes:t
    End:
-->
